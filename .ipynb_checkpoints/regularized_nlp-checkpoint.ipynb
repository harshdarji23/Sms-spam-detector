{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline, classification, pipeline, evaluation\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam_df = spark.read.csv('/datasets/sms_spam.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Encode the `type` column to be 1 for `spam` and 0 for `ham` and store the result in `sms_spam2_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ede01a8c8ef80d25d4fa8d9132b6f9c0",
     "grade": false,
     "grade_id": "cell-79e2472845514523",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sms_spam_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f3401e0aaad3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msms_spam_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'temp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msms_spam2_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select case type when \"spam\" then 1.0  else 0 end as type, text from temp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msms_spam2_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sms_spam_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sms_spam_df.createOrReplaceTempView('temp')\n",
    "sms_spam2_df=spark.sql('select case type when \"spam\" then 1.0  else 0 end as type, text from temp')\n",
    "sms_spam2_df.show(5,truncate=False)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|type|                text|\n",
      "+----+--------------------+\n",
      "| 0.0|Go until jurong p...|\n",
      "| 0.0|Ok lar... Joking ...|\n",
      "| 1.0|Free entry in 2 a...|\n",
      "| 0.0|U dun say so earl...|\n",
      "| 0.0|Nah I don't think...|\n",
      "| 1.0|FreeMsg Hey there...|\n",
      "| 0.0|Even my brother i...|\n",
      "| 0.0|As per your reque...|\n",
      "| 1.0|WINNER!! As a val...|\n",
      "| 1.0|Had your mobile 1...|\n",
      "| 0.0|I'm gonna be home...|\n",
      "| 1.0|SIX chances to wi...|\n",
      "| 1.0|URGENT! You have ...|\n",
      "| 0.0|I've been searchi...|\n",
      "| 0.0|I HAVE A DATE ON ...|\n",
      "| 1.0|XXXMobileMovieClu...|\n",
      "| 0.0|Oh k...i'm watchi...|\n",
      "| 0.0|Eh u remember how...|\n",
      "| 0.0|Fine if that's th...|\n",
      "| 1.0|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms_spam2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam2_df = sms_spam_df.\\\n",
    "    select(\n",
    "fn.when(fn.col('type')=='spam',1).otherwise(0).alias('type'),\n",
    "fn.col('text')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|type|                text|\n",
      "+----+--------------------+\n",
      "|   0|Go until jurong p...|\n",
      "|   0|Ok lar... Joking ...|\n",
      "|   1|Free entry in 2 a...|\n",
      "|   0|U dun say so earl...|\n",
      "|   0|Nah I don't think...|\n",
      "|   1|FreeMsg Hey there...|\n",
      "|   0|Even my brother i...|\n",
      "|   0|As per your reque...|\n",
      "|   1|WINNER!! As a val...|\n",
      "|   1|Had your mobile 1...|\n",
      "|   0|I'm gonna be home...|\n",
      "|   1|SIX chances to wi...|\n",
      "|   1|URGENT! You have ...|\n",
      "|   0|I've been searchi...|\n",
      "|   0|I HAVE A DATE ON ...|\n",
      "|   1|XXXMobileMovieClu...|\n",
      "|   0|Oh k...i'm watchi...|\n",
      "|   0|Eh u remember how...|\n",
      "|   0|Fine if that's th...|\n",
      "|   1|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms_spam2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam2_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3c39d9b0191d5b096f133b45d5f38f67",
     "grade": true,
     "grade_id": "cell-c6048eb3c38d3030",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_equal(\n",
    "    sms_spam2_df.groupBy('type').count().orderBy('type').rdd.map(lambda x: x['count']).collect(),\n",
    "    [4827, 747]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a pipeline that combines a `Tokenizer`, `CounterVectorizer`, and a `IDF` estimator to compute the tfidf vectors of each SMS. Fit this pipeline and assign the pipeline transformer to a variable `tfidf_pipeline`. The `Tokenizer` step should create a column `words`, the `CounterVectorizer` step should create a column `tf`, and the `IDF` step should create a column `tfidf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "521084e2063144fa97a14bef1e965fca",
     "grade": false,
     "grade_id": "cell-ab24110e63d19470",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create a Pipeline transformer and name it tfidf_pipeline\n",
    "# YOUR CODE HERE\n",
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "countvectorizer = CountVectorizer (inputCol=\"words\", outputCol=\"tf\")\n",
    "\n",
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "\n",
    "tfidf_pipeline = Pipeline(stages=[tokenizer,countvectorizer,idf]).fit(sms_spam2_df)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|type|                text|               words|                  tf|               tfidf|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   0|Go until jurong p...|[go, until, juron...|(13525,[8,42,51,6...|(13525,[8,42,51,6...|\n",
      "|   0|Ok lar... Joking ...|[ok, lar..., joki...|(13525,[5,74,404,...|(13525,[5,74,404,...|\n",
      "|   1|Free entry in 2 a...|[free, entry, in,...|(13525,[0,3,8,20,...|(13525,[0,3,8,20,...|\n",
      "|   0|U dun say so earl...|[u, dun, say, so,...|(13525,[5,22,60,1...|(13525,[5,22,60,1...|\n",
      "|   0|Nah I don't think...|[nah, i, don't, t...|(13525,[0,1,66,86...|(13525,[0,1,66,86...|\n",
      "|   1|FreeMsg Hey there...|[freemsg, hey, th...|(13525,[0,2,6,10,...|(13525,[0,2,6,10,...|\n",
      "|   0|Even my brother i...|[even, my, brothe...|(13525,[0,7,9,13,...|(13525,[0,7,9,13,...|\n",
      "|   0|As per your reque...|[as, per, your, r...|(13525,[0,10,11,4...|(13525,[0,10,11,4...|\n",
      "|   1|WINNER!! As a val...|[winner!!, as, a,...|(13525,[0,2,3,14,...|(13525,[0,2,3,14,...|\n",
      "|   1|Had your mobile 1...|[had, your, mobil...|(13525,[0,4,5,10,...|(13525,[0,4,5,10,...|\n",
      "|   0|I'm gonna be home...|[i'm, gonna, be, ...|(13525,[0,1,6,29,...|(13525,[0,1,6,29,...|\n",
      "|   1|SIX chances to wi...|[six, chances, to...|(13525,[0,6,40,48...|(13525,[0,6,40,48...|\n",
      "|   1|URGENT! You have ...|[urgent!, you, ha...|(13525,[0,2,3,4,8...|(13525,[0,2,3,4,8...|\n",
      "|   0|I've been searchi...|[i've, been, sear...|(13525,[0,1,2,3,4...|(13525,[0,1,2,3,4...|\n",
      "|   0|I HAVE A DATE ON ...|[i, have, a, date...|(13525,[1,3,14,16...|(13525,[1,3,14,16...|\n",
      "|   1|XXXMobileMovieClu...|[xxxmobilemoviecl...|(13525,[0,4,8,11,...|(13525,[0,4,8,11,...|\n",
      "|   0|Oh k...i'm watchi...|[oh, k...i'm, wat...|(13525,[159,314,4...|(13525,[159,314,4...|\n",
      "|   0|Eh u remember how...|[eh, u, remember,...|(13525,[1,5,20,46...|(13525,[1,5,20,46...|\n",
      "|   0|Fine if that's th...|[fine, if, that's...|(13525,[4,5,30,59...|(13525,[4,5,30,59...|\n",
      "|   1|England v Macedon...|[england, v, mace...|(13525,[0,4,28,81...|(13525,[0,4,28,81...|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_pipeline.transform(sms_spam2_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34ef778045b84441f525a78f9db3eb70",
     "grade": true,
     "grade_id": "cell-cd280a1ccf0f1705",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_equal([type(s) for s in tfidf_pipeline.stages],\n",
    "                              [feature.Tokenizer, feature.CountVectorizerModel, feature.IDFModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Typical spam messages contain words that are upper case. Create a dataframe `sms_spam3_df` where you add a new column `has_uppercase` which contains an integer `1` if the first sequence of uppercase letters is longer or equal to 3 and an integer `0` otherwise. We can extract sequence of 3 or more uppercase letters by using the regular expression `[A-Z]{3,}`. We will use the function `fn.regexp_extract` to find those sequences and extract the first one (e.g., with index 0) and then use `fn.length` to compute the length of such sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4a654d9e0b5d08d00aaaaa4cb3e04e30",
     "grade": false,
     "grade_id": "cell-02520df239057529",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create sms_spam3_df below\n",
    "# YOUR CODE HERE\n",
    "from pyspark.sql.functions import regexp_extract, col,length\n",
    "sms_spam3_df=sms_spam2_df.select('type','text', regexp_extract(col('text'), '([A-Z]{3,})', 1).alias('has_upppercase'))\n",
    "sms_spam3_df = sms_spam3_df.select('type','text', fn.when(fn.length(fn.col('has_upppercase')) >= 3, 1).otherwise(0).alias('has_uppercase'))\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three messages with `has_uppercase == 1` are as follows:\n",
    "\n",
    "```python\n",
    "sms_spam3_df.where('has_uppercase == 1').take(3)\n",
    "```\n",
    "\n",
    "```console\n",
    "[Row(type=1, text='WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', has_uppercase=1),\n",
    " Row(type=1, text='Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', has_uppercase=1),\n",
    " Row(type=1, text='SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', has_uppercase=1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(type=1, text='WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', has_uppercase=1),\n",
       " Row(type=1, text='Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', has_uppercase=1),\n",
       " Row(type=1, text='SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', has_uppercase=1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "sms_spam3_df.where('has_uppercase == 1').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e380d6f60200785939c9acae7e614bef",
     "grade": true,
     "grade_id": "cell-905724115443b1ad",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(set(sms_spam3_df.columns), {'has_uppercase', 'text', 'type'})\n",
    "np.testing.assert_equal(type(sms_spam3_df.schema['has_uppercase'].dataType), sql.types.IntegerType)\n",
    "np.testing.assert_equal(sms_spam3_df.rdd.map(lambda x : x['has_uppercase']).sum(), 891)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Compare models\n",
    "\n",
    "Using the following splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8293adada027540531a2727eff204198",
     "grade": false,
     "grade_id": "cell-2f05175cd6ae7f5c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = sms_spam2_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3349, 1674, 551]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[training_df.count(), validation_df.count(), testing_df.count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Create pipelines where the first stage is the `tfidf_pipeline` created above and the second stage is a `LogisticRegression` model with different regularization parameters ($\\lambda$) and elastic net mixture ($\\alpha$). Fit those pipelines to the appropriate data split.\n",
    "\n",
    "1. Logistic regression with $\\lambda=0$ and $\\alpha=0$ (assign the fitted pipeline to `lr_pipeline1`)\n",
    "2. Logistic regression with $\\lambda=0.02$ and $\\alpha=0.2$ (assign the fitted pipeline to `lr_pipeline2`)\n",
    "3. Logistic regression with $\\lambda=0.1$ and $\\alpha=0.4$ (assign the fitted pipeline to `lr_pipeline3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "02b7fefd0dd482900ba644d56b02400a",
     "grade": false,
     "grade_id": "cell-8db1a50673eea1a7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create lr_pipeline1, lr_pipeline2, and lr_pipeline3\n",
    "# YOUR CODE HERE\n",
    "\n",
    "lr1 = classification.LogisticRegression(regParam=0, elasticNetParam=0, labelCol = 'type', featuresCol = 'tfidf')\n",
    "lr_pipeline1 = Pipeline(stages=[tfidf_pipeline, lr1]).fit(training_df)\n",
    "lr2 = classification.LogisticRegression(regParam=0.02, elasticNetParam=0.2, labelCol = 'type', featuresCol = 'tfidf')\n",
    "lr_pipeline2 = Pipeline(stages=[tfidf_pipeline, lr2]).fit(training_df)\n",
    "lr3 = classification.LogisticRegression(regParam=0.1, elasticNetParam=0.4, labelCol = 'type', featuresCol = 'tfidf')\n",
    "lr_pipeline3 = Pipeline(stages=[tfidf_pipeline, lr3]).fit(training_df)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd388632281a19de36557ec7a00af21d",
     "grade": true,
     "grade_id": "cell-bc59c22c523a9016",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts)\n",
    "np.testing.assert_equal(type(lr_pipeline1), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(lr_pipeline2), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(lr_pipeline3), pipeline.PipelineModel)\n",
    "np.testing.assert_array_equal([type(s) for s in lr_pipeline1.stages],\n",
    "                              [pipeline.PipelineModel, classification.LogisticRegressionModel])\n",
    "np.testing.assert_array_equal([type(s) for s in lr_pipeline2.stages],\n",
    "                              [pipeline.PipelineModel, classification.LogisticRegressionModel])\n",
    "np.testing.assert_array_equal([type(s) for s in lr_pipeline3.stages],\n",
    "                              [pipeline.PipelineModel, classification.LogisticRegressionModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Use the evaluator object defined below to compute the area under the curve of your predictors. For example, to compute the area under the curve of pipeline 1 for a dataframe `df`, you would run\n",
    "\n",
    "```python\n",
    "evaluator.evaluate(lr_pipeline1.transform(df))\n",
    "```\n",
    "\n",
    "Assign the AUC of the three models to the variables `AUC1`, `AUC2`, and `AUC3`, and and assign the pipeline with the best model to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "74638d21bd238bcc28672143908e8b8c",
     "grade": false,
     "grade_id": "cell-44d4a941d4aef83e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.BinaryClassificationEvaluator(labelCol='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the AUC on training of the first model is perfect:\n",
    "\n",
    "```\n",
    "evaluator.evaluate(lr_pipeline1.transform(training_df))\n",
    "```\n",
    "\n",
    "```console\n",
    "1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d2b1fd1d3f5e9dbcd1986f7c6486293",
     "grade": false,
     "grade_id": "cell-a9d883059572796b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 AUC:  0.9557218489415972\n",
      "Model 2 AUC:  0.9871555611031791\n",
      "Model 3 AUC:  0.9686667539402503\n"
     ]
    }
   ],
   "source": [
    "# print the AUC for the three models as follows\n",
    "# print(\"Model 1 AUC: \", evaluator.evaluate(....))\n",
    "# etc\n",
    "# finally, based on these, assign the best validated \n",
    "# model to a variable best_model\n",
    "# YOUR CODE HERE\n",
    "AUC1 = evaluator.evaluate(lr_pipeline1.transform(validation_df))\n",
    "print(\"Model 1 AUC: \", AUC1)\n",
    "AUC2 = evaluator.evaluate(lr_pipeline2.transform(validation_df))\n",
    "print(\"Model 2 AUC: \", AUC2)\n",
    "AUC3 = evaluator.evaluate(lr_pipeline3.transform(validation_df))\n",
    "print(\"Model 3 AUC: \", AUC3)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c76a13060b46900aa055920ae5f6a2f",
     "grade": true,
     "grade_id": "cell-29d52d2cec5c8a1e",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_array_equal([type(AUC1), type(AUC2), type(AUC3)],\n",
    "                             [float, float, float])\n",
    "# AUC less than 1\n",
    "np.testing.assert_array_less([AUC1, AUC2, AUC3], [1, 1, 1])\n",
    "# AUC more than 0.5\n",
    "np.testing.assert_array_less([.5, .5, .5],\n",
    "                            [AUC1, AUC2, AUC3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.5: Choose best model\n",
    "\n",
    "Using the right split and the best model selected before, compute the generalization performance and assign it to a variable `AUC_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7780410d49dd0727bea11bcfa2ec75de",
     "grade": false,
     "grade_id": "cell-2d30a81f9c08fc5d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# assign to AUC_best the AUC of the best model selected before\n",
    "# YOUR CODE HERE\n",
    "AUC_best = evaluator.evaluate(lr_pipeline2.transform(testing_df))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "77cef30af04406aeee070bae31e75129",
     "grade": true,
     "grade_id": "cell-dc8fd7d7ce658642",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_approx_equal(AUC_best, \n",
    "                               0.976126746201693, significant=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.6: Inference\n",
    "\n",
    "Use the pipeline 2 fitted above (`lr_pipeline2`) to create Pandas dataframes that contain the most negative words and the most positive words. In particular, create a dataframe `positive_words` with the columns `word` and `weight` with the top 20 positive words, sorted by descending coefficient. Similarly create a `negative_words` Pandas dataframe with the top 20 negative words where the coefficient are sorted in ascending order. **Hint: follow the `sentiment_analysis.ipynb` notebook in the repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b517fb83f670ea60b1fdb1580356a410",
     "grade": false,
     "grade_id": "cell-9fa9de453a36f8d2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create positive_words and negative_words pandas dataframe below\n",
    "# YOUR CODE HERE\n",
    "vocabulary = lr_pipeline2.stages[0].stages[-2].vocabulary\n",
    "weights = lr_pipeline2.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})\n",
    "negative_words = coeffs_df.sort_values('weight').head(20)\n",
    "positive_words = coeffs_df.sort_values('weight', ascending=False).head(20)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>widelive.com/index.</td>\n",
       "      <td>0.590870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12237</th>\n",
       "      <td>08714712388</td>\n",
       "      <td>0.533567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>call</td>\n",
       "      <td>0.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.513278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>gbp/sms</td>\n",
       "      <td>0.468274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      word    weight\n",
       "3555   widelive.com/index.  0.590870\n",
       "12237          08714712388  0.533567\n",
       "15                    call  0.517100\n",
       "81                     txt  0.513278\n",
       "9064               gbp/sms  0.468274"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine positive vocabulary\n",
    "positive_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>-0.162493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>fighting</td>\n",
       "      <td>-0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>dificult</td>\n",
       "      <td>-0.059061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>fightng</td>\n",
       "      <td>-0.059061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>lose.</td>\n",
       "      <td>-0.059061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    weight\n",
       "1            i -0.162493\n",
       "2444  fighting -0.060939\n",
       "3221  dificult -0.059061\n",
       "3371   fightng -0.059061\n",
       "3332     lose. -0.059061"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine solutions\n",
    "negative_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `positive_words` and `negative_words` dataframe should look like this:\n",
    "\n",
    "```python\n",
    "positive_words.head()\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>word</th>\n",
    "      <th>weight</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>3555</th>\n",
    "      <td>widelive.com/index.</td>\n",
    "      <td>0.590870</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12237</th>\n",
    "      <td>08714712388</td>\n",
    "      <td>0.533567</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>call</td>\n",
    "      <td>0.517100</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>81</th>\n",
    "      <td>txt</td>\n",
    "      <td>0.513278</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9064</th>\n",
    "      <td>gbp/sms</td>\n",
    "      <td>0.468274</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "and \n",
    "\n",
    "```python\n",
    "negative_words.head()\n",
    "```\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>word</th>\n",
    "      <th>weight</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>i</td>\n",
    "      <td>-0.162493</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2444</th>\n",
    "      <td>fighting</td>\n",
    "      <td>-0.060939</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3221</th>\n",
    "      <td>dificult</td>\n",
    "      <td>-0.059061</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3371</th>\n",
    "      <td>fightng</td>\n",
    "      <td>-0.059061</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3332</th>\n",
    "      <td>lose.</td>\n",
    "      <td>-0.059061</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9d1c1cfaa5326d7403d0c48891dea0b0",
     "grade": true,
     "grade_id": "cell-5926b249c3d8d910",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (5 pts)\n",
    "np.testing.assert_equal(set(positive_words.columns), {'weight', 'word'})\n",
    "np.testing.assert_equal(set(negative_words.columns), {'weight', 'word'})\n",
    "np.testing.assert_approx_equal(positive_words.weight.sum(), 8.3701485692317927, significant=2)\n",
    "np.testing.assert_approx_equal(negative_words.weight.sum(), -0.6661952507442954, significant=2)\n",
    "np.testing.assert_array_less(positive_words.weight.iloc[-1], positive_words.weight.iloc[0])\n",
    "np.testing.assert_array_less(negative_words.weight.iloc[0], negative_words.weight.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.7\n",
    "Use the dataframe `sms_spam3_df` to create a model where the first feature is `has_uppercase` and the next set of features are the tfidf of the text. Perform feature engineering in all features using a max absolute scaler ([`MaxAbsScaler`](https://spark.apache.org/docs/2.0.2/ml-features.html#maxabsscaler)). Do a logistic regression on the resulting scaled features with regularization parameter $\\lambda = 0.2$ and elastic net mixture $\\alpha=0.1$ for the entire data (all of `sms_spam3_df`). Since you have scaled all features to be within the same range, you can compare them. \n",
    "\n",
    "**(5 pts)** with code and comments, answer below\n",
    "\n",
    "1. is `has_uppercase` a feature that is positively or negative related to an SMS being spam?\n",
    "2. what is the ratio of the coefficient of `has_uppercase` to the biggest positive tfidf coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b811be2a38e793ee1cfdbc0c0624addb",
     "grade": true,
     "grade_id": "cell-63ad341d276b5971",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/daniel-acuna/pyspark_pipes.git\n",
      "  Cloning https://github.com/daniel-acuna/pyspark_pipes.git to /tmp/pip-req-build-_jwl5rq9\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyspark-pipes==0.1 from git+https://github.com/daniel-acuna/pyspark_pipes.git in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pyspark in /usr/local/spark-2.4.0-bin-hadoop2.7/python (from pyspark-pipes==0.1) (2.4.0)\n",
      "Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.6/site-packages (from pyspark->pyspark-pipes==0.1) (0.10.7)\n",
      "Building wheels for collected packages: pyspark-pipes\n",
      "  Running setup.py bdist_wheel for pyspark-pipes ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-79b03m_v/wheels/58/e0/91/9f974ba72a9ea731a32cba0cccc17064e7d959a8f37e00263f\n",
      "Successfully built pyspark-pipes\n",
      "has_uppercase feature is positively related to an SMS being spam with a coefficient of: 0.9289178747599827\n",
      "The ratio of the coefficient of has_uppercase to the biggest positive tfidf coefficient is : 0.4617005798337622\n"
     ]
    }
   ],
   "source": [
    "# your code and comments below\n",
    "# YOUR CODE HERE\n",
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer_df3 = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "from pyspark.ml.feature import CountVectorizer,VectorAssembler\n",
    "countvectorizer_df3 = CountVectorizer(inputCol=\"words\", outputCol=\"tf\")\n",
    "from pyspark.ml.feature import  IDF\n",
    "idf_3 = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "assembler = VectorAssembler(inputCols=[\"has_uppercase\", \"tfidf\"],outputCol=\"features\")\n",
    "\n",
    "tfidf_pipeline_upper = Pipeline(stages=[tokenizer_df3,countvectorizer_df3,idf_3,assembler]).fit(sms_spam3_df)\n",
    "df_upper = tfidf_pipeline_upper.transform(sms_spam3_df)\n",
    "\n",
    "!pip install git+https://github.com/daniel-acuna/pyspark_pipes.git\n",
    "from pyspark_pipes import pipe\n",
    "\n",
    "\n",
    "scaled_model=pipe(feature.VectorAssembler(inputCols=['has_uppercase','tfidf']),feature.MaxAbsScaler(),classification.LogisticRegression(regParam=0.2, elasticNetParam=0.1, labelCol = 'type'))\n",
    "scaled_model_fitted = scaled_model.fit(df_upper)\n",
    "\n",
    "my_coeff=scaled_model_fitted.stages[-1].coefficients\n",
    "has_uppercase_coeff = my_coeff.toArray()[0]\n",
    "print('has_uppercase feature is positively related to an SMS being spam with a coefficient of:',has_uppercase_coeff)\n",
    "\n",
    "max_coeff=my_coeff.toArray().max()\n",
    "my_ratio=has_uppercase_coeff/max_coeff\n",
    "\n",
    "print('The ratio of the coefficient of has_uppercase to the biggest positive tfidf coefficient is :',my_ratio)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
